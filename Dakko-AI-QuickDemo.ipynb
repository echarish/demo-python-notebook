{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Notebook is the sample Demo setup for working with DakkoAI Client Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dakko library\n",
    "from dakkoai import (\n",
    "    DakkoAIClient,\n",
    "    DakkoRegistrationModel,\n",
    "    DakkoSearch,\n",
    ")\n",
    "\n",
    "# Import supporting DataScience lib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from collections import Counter\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "# Create dakko_client\n",
    "dakko_client = DakkoAIClient()\n",
    "\n",
    "# Register new crypto Data Scientist\n",
    "user_data = DakkoRegistrationModel(\n",
    "    email=\"user@example.com\", first_name=\"John\", last_name=\"Doe\", user_name=\"johndoe\"\n",
    ")\n",
    "\n",
    "status = dakko_client.register(user_data)\n",
    "print(f\"Register User: {status}\")\n",
    "print(dakko_client.client_credentials.model_dump())\n",
    "\n",
    "# Get access credentials for further connection to Dakko\n",
    "status = dakko_client.get_access_token()\n",
    "\n",
    "print(f\"Getting access token: {status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ts = int(liqiq[\"timestamp\"].max().timestamp())\n",
    "ts_ago = int((liqiq[\"timestamp\"].max() - timedelta(days=4)).timestamp())\n",
    "SEARCH_ADDRESS = \"0xAD9eF19e289dcbC9AB27b83D2dF53CDEFF60f02D\".lower()\n",
    "\n",
    "dakko_sql = DakkoSearch(\n",
    "    query=f\"\"\"\n",
    "    \n",
    "    WITH \n",
    "        Constants AS (\n",
    "            SELECT \n",
    "                '{SEARCH_ADDRESS}' AS contract, \n",
    "                18 AS dec0, \n",
    "                18 AS dec1,\n",
    "                timestamp({max_ts}) AS max_ts,\n",
    "                timestamp({ts_ago}) AS ts_ago,\n",
    "                30 as search_width\n",
    "        ), \n",
    "        PreparedData AS (\n",
    "            SELECT \n",
    "                `timestamp`,\n",
    "                pow(sqrtPriceX96 / pow(2, 96), 2) * pow(10, dec0 - dec1) AS price,\n",
    "                tick \n",
    "            FROM dakko_poc.eth_demo.token_swaps_raw, Constants\n",
    "            WHERE address = lower(contract)\n",
    "        ) \n",
    "        \n",
    "    SELECT * FROM (SELECT price, tick\n",
    "    FROM PreparedData, Constants \n",
    "    WHERE abs(TIMESTAMPDIFF(SECOND, `timestamp`, max_ts)) < search_width\n",
    "    ORDER BY `timestamp` DESC\n",
    "    LIMIT 1)\n",
    "    UNION ALL\n",
    "    SELECT * FROM (SELECT price, tick\n",
    "    FROM PreparedData, Constants \n",
    "    WHERE abs(TIMESTAMPDIFF(SECOND, `timestamp`, ts_ago)) < search_width\n",
    "    ORDER BY `timestamp` DESC\n",
    "    LIMIT 1)\n",
    "    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "last_swaps = dakko_client.get_query_results(dakko_sql).dataframe\n",
    "last_price, last_price_past_snap = last_swaps.price.values\n",
    "last_tick, last_tick_past_snap = last_swaps.tick.astype(int).values\n",
    "\n",
    "SEARCH_ADDRESS = \"0xAD9eF19e289dcbC9AB27b83D2dF53CDEFF60f02D\".lower()\n",
    "\n",
    "dakko_ld_sql = DakkoSearch(\n",
    "    query=f\"\"\"\n",
    "    with \n",
    "        txhashes as (\n",
    "            select distinct transactionHash \n",
    "            from dakko_poc.eth_bronze.parsed_transaction_logs_refine \n",
    "            where address = \"{SEARCH_ADDRESS}\" \n",
    "            and event = \"Mint\"\n",
    "        ), \n",
    "        tokenIds as (\n",
    "            select indexed_args \n",
    "            from dakko_poc.eth_bronze.parsed_transaction_logs_refine \n",
    "            where event in (\"IncreaseLiquidity\", \"DecreaseLiquidity\") \n",
    "            and transactionHash in (select transactionHash from txhashes)\n",
    "        ) \n",
    "        select distinct * from (\n",
    "            select * \n",
    "            from dakko_poc.eth_bronze.parsed_transaction_logs_refine \n",
    "            where address = \"{SEARCH_ADDRESS}\" \n",
    "            and event in (\"Mint\", \"Burn\") \n",
    "            union all \n",
    "            select * from \n",
    "            dakko_poc.eth_bronze.parsed_transaction_logs_refine \n",
    "            where event in (\"IncreaseLiquidity\", \"DecreaseLiquidity\") \n",
    "            and indexed_args in (select indexed_args from tokenIds)\n",
    "        )\n",
    "        join (select indexed_names, not_indexed_names, signature from dakko_poc.eth_static.event_registry_with_meta)\n",
    "        using (signature)\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "ld_df = dakko_client.get_query_results(dakko_ld_sql).dataframe\n",
    "ld_df\n",
    "\n",
    "def parse_args(df, names: str, args: str):\n",
    "    # get first row of the column\n",
    "\n",
    "    unique_names = df[names].unique()\n",
    "    new_columns = [x.split(\",\") for x in unique_names]\n",
    "    new_columns = reduce(lambda x, y: x + y, new_columns)\n",
    "\n",
    "    df[new_columns] = None\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    for combo in unique_names:\n",
    "        slice_df = df[df[names] == combo].copy()\n",
    "        slice_df[combo.split(\",\")] = slice_df[args].str.split(\";\", expand=True)\n",
    "        new_df = pd.concat([new_df, slice_df])\n",
    "\n",
    "    new_df.drop(columns=[args, names], inplace=True)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "liqiq = parse_args(ld_df, \"indexed_names\", \"indexed_args\")\n",
    "liqiq = parse_args(liqiq, \"not_indexed_names\", \"not_indexed_args\")\n",
    "liqiq[\"timestamp\"] = pd.to_datetime(liqiq[\"timestamp\"])\n",
    "\n",
    "# copy events with token id\n",
    "liqiq_id = liqiq[liqiq.event.isin([\"DecreaseLiquidity\", \"IncreaseLiquidity\"])].copy()\n",
    "\n",
    "# copy events without token id\n",
    "liquiq_not_id = liqiq[\n",
    "    ~liqiq.event.isin([\"DecreaseLiquidity\", \"IncreaseLiquidity\"])\n",
    "].copy()\n",
    "\n",
    "# build mapping between positions and tick ranges\n",
    "tokenId_to_ticks = (\n",
    "    (\n",
    "        liqiq_id.drop(columns=[\"tickUpper\", \"tickLower\"]).merge(\n",
    "            liquiq_not_id[[\"transactionHash\", \"tickUpper\", \"tickLower\"]],\n",
    "            how=\"inner\",\n",
    "            on=\"transactionHash\",\n",
    "        )\n",
    "    )[[\"tokenId\", \"tickUpper\", \"tickLower\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .to_dict(\"records\")\n",
    ")\n",
    "\n",
    "# remap\n",
    "tokenId_to_ticks_new = dict()\n",
    "\n",
    "for x in tokenId_to_ticks:\n",
    "    tokenId_to_ticks_new[x[\"tokenId\"]] = (x[\"tickUpper\"], x[\"tickLower\"])\n",
    "\n",
    "# apply for original df\n",
    "\n",
    "liqiq[\"tickUpper\"] = liqiq.apply(\n",
    "    lambda x: (\n",
    "        tokenId_to_ticks_new[x[\"tokenId\"]][0]\n",
    "        if x[\"tokenId\"] is not None\n",
    "        else x[\"tickUpper\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "liqiq[\"tickLower\"] = liqiq.apply(\n",
    "    lambda x: (\n",
    "        tokenId_to_ticks_new[x[\"tokenId\"]][1]\n",
    "        if x[\"tokenId\"] is not None\n",
    "        else x[\"tickLower\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# rebuild liquidity column using all events now\n",
    "liqiq.liquidity = liqiq.apply(\n",
    "    lambda x: float(x.liquidity) if x.liquidity is not None else float(x.amount), axis=1\n",
    ")\n",
    "\n",
    "# convert to numeric\n",
    "for col in [\"amount0\", \"amount1\"]:\n",
    "    liqiq[col] = liqiq[col].astype(float)\n",
    "\n",
    "liqiq.tickLower = liqiq.tickLower.astype(int)\n",
    "liqiq.tickUpper = liqiq.tickUpper.astype(int)\n",
    "\n",
    "# add multiplier for corresponding events\n",
    "for col in [\"liquidity\", \"amount0\", \"amount1\"]:\n",
    "    liqiq[col] *= liqiq.event.apply(\n",
    "        lambda x: -1 if x in [\"DecreaseLiquidity\", \"Burn\"] else 1\n",
    "    )\n",
    "    \n",
    "    \n",
    "from datetime import timedelta\n",
    "# extract liquidity distribution using liquidity dataframe preprocessed\n",
    "def get_liq_ticks(df: pd.DataFrame, dec0: int = 18, dec1: int = 18):\n",
    "    unique_ticks = sorted(set(df[\"tickLower\"]).union(set(df[\"tickUpper\"])))\n",
    "\n",
    "    tick_liquidity = pd.DataFrame(unique_ticks, columns=[\"tick\"]).set_index(\"tick\")\n",
    "    tick_liquidity[\"totalLiquidity\"] = 0\n",
    "    tick_liquidity[\"amount0locked\"] = 0\n",
    "    tick_liquidity[\"amount1locked\"] = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        tick_liquidity.loc[\n",
    "            row[\"tickLower\"] : row[\"tickUpper\"], \"totalLiquidity\"\n",
    "        ] += row[\"liquidity\"]\n",
    "        tick_liquidity.loc[row[\"tickLower\"] : row[\"tickUpper\"], \"amount0locked\"] += row[\n",
    "            \"amount0\"\n",
    "        ]\n",
    "        tick_liquidity.loc[row[\"tickLower\"] : row[\"tickUpper\"], \"amount1locked\"] += row[\n",
    "            \"amount1\"\n",
    "        ]\n",
    "\n",
    "    tick_liquidity = tick_liquidity.reset_index()\n",
    "\n",
    "    tick_liquidity[\"price\"] = 1.0001 ** tick_liquidity[\"tick\"] * 10 ** (dec1 - dec0)\n",
    "\n",
    "    tick_liquidity[\"tick_width\"] = tick_liquidity[\"tick\"].diff().shift(-1).fillna(0)\n",
    "    tick_liquidity[\"price_width\"] = tick_liquidity[\"price\"].diff().shift(-1).fillna(0)\n",
    "\n",
    "    return tick_liquidity\n",
    "\n",
    "# last available liquidity state\n",
    "tick_liquidity = get_liq_ticks(liqiq)\n",
    "\n",
    "# liquidity state 4 days before last state available\n",
    "tick_liquidity_past_snap = get_liq_ticks(\n",
    "    liqiq[liqiq[\"timestamp\"] < liqiq[\"timestamp\"].max() - timedelta(days=4)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Liquidity distribution on Tick space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.bar(\n",
    "    tick_liquidity_past_snap[\"tick\"],\n",
    "    tick_liquidity_past_snap[\"totalLiquidity\"],\n",
    "    width=tick_liquidity_past_snap[\"tick_width\"],\n",
    "    align=\"edge\",\n",
    "    alpha=0.5,\n",
    "    color=\"gray\",\n",
    "    label=\"Liquidity 4 days ago\",\n",
    ")\n",
    "ax.vlines(\n",
    "    last_tick_past_snap,\n",
    "    0,\n",
    "    tick_liquidity_past_snap[\"totalLiquidity\"].max(),\n",
    "    color=\"gray\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=1,\n",
    "    label=\"Price 4 days ago\",\n",
    ")\n",
    "\n",
    "ax.bar(\n",
    "    tick_liquidity[\"tick\"],\n",
    "    tick_liquidity[\"totalLiquidity\"],\n",
    "    width=tick_liquidity[\"tick_width\"],\n",
    "    align=\"edge\",\n",
    "    alpha=1,\n",
    "    color=\"violet\",\n",
    "    label=\"Liquidity now\",\n",
    ")\n",
    "ax.vlines(\n",
    "    last_tick,\n",
    "    0,\n",
    "    tick_liquidity[\"totalLiquidity\"].max(),\n",
    "    color=\"red\",\n",
    "    alpha=1,\n",
    "    label=\"Current price\",\n",
    ")\n",
    "\n",
    "ax.set_xlim(-8e4, -4e4)\n",
    "ax.legend()\n",
    "\n",
    "ax.set_ylabel(\"Liquidity\", labelpad=15)\n",
    "ax.set_xlabel(\"Tick\", labelpad=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
